{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13262730,"sourceType":"datasetVersion","datasetId":8404512}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-04T19:04:03.101188Z","iopub.execute_input":"2025-10-04T19:04:03.101421Z","iopub.status.idle":"2025-10-04T19:04:05.252537Z","shell.execute_reply.started":"2025-10-04T19:04:03.101403Z","shell.execute_reply":"2025-10-04T19:04:05.251704Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/flowers102-dataset/102flowers.tgz\n/kaggle/input/flowers102-dataset/imagelabels.mat\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers as tfl\nimport numpy as np\nimport os\nimport tarfile\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nimport scipy.io","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T19:04:05.253409Z","iopub.execute_input":"2025-10-04T19:04:05.253878Z","iopub.status.idle":"2025-10-04T19:04:20.640265Z","shell.execute_reply.started":"2025-10-04T19:04:05.253855Z","shell.execute_reply":"2025-10-04T19:04:20.639681Z"}},"outputs":[{"name":"stderr","text":"2025-10-04 19:04:07.304553: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759604647.546214      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759604647.613045      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"dataset_path = \"/kaggle/input/flowers102-dataset\"\nimages_path = os.path.join(dataset_path, \"102flowers.tgz\")\nlabels_path = os.path.join(dataset_path, \"imagelabels.mat\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T19:04:20.641570Z","iopub.execute_input":"2025-10-04T19:04:20.642108Z","iopub.status.idle":"2025-10-04T19:04:20.645595Z","shell.execute_reply.started":"2025-10-04T19:04:20.642087Z","shell.execute_reply":"2025-10-04T19:04:20.645013Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"if not os.path.exists(\"102flowers\"):\n    tar = tarfile.open(images_path)\n    tar.extractall()\n    tar.close()\n    print(\"Images extracted successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T19:04:20.646258Z","iopub.execute_input":"2025-10-04T19:04:20.646473Z","iopub.status.idle":"2025-10-04T19:04:27.480309Z","shell.execute_reply.started":"2025-10-04T19:04:20.646448Z","shell.execute_reply":"2025-10-04T19:04:27.479674Z"}},"outputs":[{"name":"stdout","text":"Images extracted successfully!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"labels = scipy.io.loadmat(labels_path)['labels'][0]\n\nimage_dir = \"jpg\" if os.path.exists(\"jpg\") else \"102flowers/jpg\"\nimage_files = sorted(os.listdir(image_dir))\n\nimages = []\nimage_labels = []\n\nfor i, file in enumerate(image_files[:2000]):\n    img_path = os.path.join(image_dir, file)\n    img = Image.open(img_path).resize((64, 64))\n    img = np.array(img)\n    if img.shape == (64, 64, 3):  \n        images.append(img)\n        image_labels.append(labels[i] - 1)\n\nimages = np.array(images) / 255.0\nimage_labels = np.array(image_labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T19:04:27.481015Z","iopub.execute_input":"2025-10-04T19:04:27.481221Z","iopub.status.idle":"2025-10-04T19:04:36.320277Z","shell.execute_reply.started":"2025-10-04T19:04:27.481204Z","shell.execute_reply":"2025-10-04T19:04:36.319492Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(images, image_labels, test_size=0.2, random_state=42)\n\nprint(\"Train shape:\", X_train.shape)\nprint(\"Test shape:\", X_test.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T19:04:36.321389Z","iopub.execute_input":"2025-10-04T19:04:36.321611Z","iopub.status.idle":"2025-10-04T19:04:36.388494Z","shell.execute_reply.started":"2025-10-04T19:04:36.321594Z","shell.execute_reply":"2025-10-04T19:04:36.387882Z"}},"outputs":[{"name":"stdout","text":"Train shape: (1600, 64, 64, 3)\nTest shape: (400, 64, 64, 3)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def flower102model(input_shape=(64,64,3), num_classes=102):\n    model = tf.keras.Sequential([\n        tf.keras.layers.ZeroPadding2D(padding=3, input_shape=input_shape),\n        tf.keras.layers.Conv2D(filters=20,kernel_size=(3,3), strides=(1,1), padding='same'),\n        tf.keras.layers.BatchNormalization(axis=3),\n        tf.keras.layers.ReLU(),\n        tf.keras.layers.Conv2D(filters=20,kernel_size=(3,3), strides=(1,1), padding='same'),\n        tf.keras.layers.BatchNormalization(axis=3),\n        tf.keras.layers.ReLU(),\n        tf.keras.layers.Conv2D(filters=20,kernel_size=(3,3), strides=(1,1), padding='same'),\n        tf.keras.layers.BatchNormalization(axis=3),\n        tf.keras.layers.ReLU(),\n        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n\n        tf.keras.layers.Conv2D(filters=48,kernel_size=(3,3), strides=(1,1), padding='same'),\n        tf.keras.layers.BatchNormalization(axis=3),\n        tf.keras.layers.ReLU(),\n        tf.keras.layers.Conv2D(filters=48,kernel_size=(3,3), strides=(1,1), padding='same'),\n        tf.keras.layers.BatchNormalization(axis=3),\n        tf.keras.layers.ReLU(),\n        tf.keras.layers.Conv2D(filters=48,kernel_size=(3,3), strides=(1,1), padding='same'),\n        tf.keras.layers.BatchNormalization(axis=3),\n        tf.keras.layers.ReLU(),\n        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(200,activation='relu'),\n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(100,activation='relu'),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(num_classes, activation='softmax')\n        \n    ])\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T19:34:45.059903Z","iopub.execute_input":"2025-10-04T19:34:45.060480Z","iopub.status.idle":"2025-10-04T19:34:45.067775Z","shell.execute_reply.started":"2025-10-04T19:34:45.060456Z","shell.execute_reply":"2025-10-04T19:34:45.067036Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"model = flower102model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T19:34:45.572338Z","iopub.execute_input":"2025-10-04T19:34:45.572942Z","iopub.status.idle":"2025-10-04T19:34:45.697221Z","shell.execute_reply.started":"2025-10-04T19:34:45.572921Z","shell.execute_reply":"2025-10-04T19:34:45.696656Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T19:34:48.857887Z","iopub.execute_input":"2025-10-04T19:34:48.858152Z","iopub.status.idle":"2025-10-04T19:34:48.866597Z","shell.execute_reply.started":"2025-10-04T19:34:48.858134Z","shell.execute_reply":"2025-10-04T19:34:48.865979Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T19:34:49.187589Z","iopub.execute_input":"2025-10-04T19:34:49.188292Z","iopub.status.idle":"2025-10-04T19:34:49.214981Z","shell.execute_reply.started":"2025-10-04T19:34:49.188267Z","shell.execute_reply":"2025-10-04T19:34:49.214430Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ zero_padding2d_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)                 │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m20\u001b[0m)     │           \u001b[38;5;34m560\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m20\u001b[0m)     │            \u001b[38;5;34m80\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_12 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m20\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m20\u001b[0m)     │         \u001b[38;5;34m3,620\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m20\u001b[0m)     │            \u001b[38;5;34m80\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_13 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m20\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m20\u001b[0m)     │         \u001b[38;5;34m3,620\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m20\u001b[0m)     │            \u001b[38;5;34m80\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_14 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m20\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m20\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m48\u001b[0m)     │         \u001b[38;5;34m8,688\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m48\u001b[0m)     │           \u001b[38;5;34m192\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_15 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m48\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m48\u001b[0m)     │        \u001b[38;5;34m20,784\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m48\u001b[0m)     │           \u001b[38;5;34m192\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_16 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m48\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m48\u001b[0m)     │        \u001b[38;5;34m20,784\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m48\u001b[0m)     │           \u001b[38;5;34m192\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_17 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m48\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m48\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13872\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │     \u001b[38;5;34m2,774,600\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m20,100\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m102\u001b[0m)            │        \u001b[38;5;34m10,302\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ zero_padding2d_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)                 │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">560</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,620</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,620</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,688</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,784</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,784</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13872</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,774,600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,100</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,302</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,863,874\u001b[0m (10.92 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,863,874</span> (10.92 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,863,466\u001b[0m (10.92 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,863,466</span> (10.92 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m408\u001b[0m (1.59 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">408</span> (1.59 KB)\n</pre>\n"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(64)\ntest_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(64)\nhistory = model.fit(train_dataset, epochs=100, validation_data=test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T19:34:50.708197Z","iopub.execute_input":"2025-10-04T19:34:50.708813Z","iopub.status.idle":"2025-10-04T19:36:00.091387Z","shell.execute_reply.started":"2025-10-04T19:34:50.708791Z","shell.execute_reply":"2025-10-04T19:36:00.090849Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 92ms/step - accuracy: 0.0645 - loss: 6.0524 - val_accuracy: 0.1950 - val_loss: 4.0498\nEpoch 2/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.1625 - loss: 3.0074 - val_accuracy: 0.1225 - val_loss: 3.2039\nEpoch 3/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.2308 - loss: 2.4895 - val_accuracy: 0.0925 - val_loss: 2.9627\nEpoch 4/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.2770 - loss: 2.2909 - val_accuracy: 0.1075 - val_loss: 2.8029\nEpoch 5/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.3084 - loss: 2.1937 - val_accuracy: 0.0875 - val_loss: 2.8588\nEpoch 6/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.3479 - loss: 2.0203 - val_accuracy: 0.0675 - val_loss: 2.9412\nEpoch 7/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.3325 - loss: 2.0148 - val_accuracy: 0.0700 - val_loss: 3.3060\nEpoch 8/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.3729 - loss: 1.9490 - val_accuracy: 0.0950 - val_loss: 3.3177\nEpoch 9/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.3968 - loss: 1.8465 - val_accuracy: 0.1025 - val_loss: 2.8907\nEpoch 10/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4186 - loss: 1.7442 - val_accuracy: 0.1025 - val_loss: 2.8384\nEpoch 11/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4345 - loss: 1.6491 - val_accuracy: 0.1350 - val_loss: 2.9785\nEpoch 12/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4619 - loss: 1.5747 - val_accuracy: 0.1475 - val_loss: 2.8999\nEpoch 13/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4736 - loss: 1.4887 - val_accuracy: 0.2375 - val_loss: 2.3559\nEpoch 14/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4868 - loss: 1.5426 - val_accuracy: 0.2775 - val_loss: 2.1625\nEpoch 15/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5371 - loss: 1.3894 - val_accuracy: 0.2775 - val_loss: 2.1622\nEpoch 16/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5579 - loss: 1.2674 - val_accuracy: 0.2700 - val_loss: 2.4225\nEpoch 17/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5462 - loss: 1.3315 - val_accuracy: 0.4150 - val_loss: 1.6158\nEpoch 18/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5593 - loss: 1.2703 - val_accuracy: 0.4150 - val_loss: 1.6702\nEpoch 19/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5716 - loss: 1.2390 - val_accuracy: 0.4300 - val_loss: 1.6503\nEpoch 20/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5547 - loss: 1.2374 - val_accuracy: 0.5375 - val_loss: 1.2450\nEpoch 21/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6055 - loss: 1.1062 - val_accuracy: 0.5125 - val_loss: 1.3747\nEpoch 22/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6102 - loss: 1.1412 - val_accuracy: 0.5025 - val_loss: 1.4253\nEpoch 23/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5988 - loss: 1.1049 - val_accuracy: 0.5700 - val_loss: 1.2543\nEpoch 24/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5918 - loss: 1.1330 - val_accuracy: 0.5550 - val_loss: 1.3447\nEpoch 25/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6283 - loss: 1.0311 - val_accuracy: 0.6275 - val_loss: 1.2547\nEpoch 26/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6450 - loss: 1.0170 - val_accuracy: 0.5875 - val_loss: 1.1886\nEpoch 27/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6471 - loss: 0.9914 - val_accuracy: 0.6125 - val_loss: 1.0909\nEpoch 28/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6748 - loss: 0.9514 - val_accuracy: 0.5500 - val_loss: 1.2856\nEpoch 29/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6692 - loss: 0.9318 - val_accuracy: 0.4975 - val_loss: 1.6556\nEpoch 30/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6855 - loss: 0.8472 - val_accuracy: 0.5875 - val_loss: 1.2550\nEpoch 31/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6706 - loss: 0.8972 - val_accuracy: 0.6425 - val_loss: 1.0774\nEpoch 32/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7230 - loss: 0.7419 - val_accuracy: 0.5725 - val_loss: 1.5779\nEpoch 33/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6918 - loss: 0.8675 - val_accuracy: 0.6475 - val_loss: 1.1595\nEpoch 34/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7050 - loss: 0.8235 - val_accuracy: 0.6450 - val_loss: 1.3629\nEpoch 35/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6902 - loss: 0.8623 - val_accuracy: 0.6475 - val_loss: 1.2293\nEpoch 36/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7031 - loss: 0.7855 - val_accuracy: 0.5825 - val_loss: 2.0332\nEpoch 37/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7053 - loss: 0.8052 - val_accuracy: 0.6325 - val_loss: 1.2312\nEpoch 38/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7320 - loss: 0.7469 - val_accuracy: 0.7075 - val_loss: 1.0198\nEpoch 39/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7298 - loss: 0.7337 - val_accuracy: 0.6825 - val_loss: 1.0706\nEpoch 40/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7183 - loss: 0.7297 - val_accuracy: 0.6950 - val_loss: 0.9366\nEpoch 41/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7250 - loss: 0.7200 - val_accuracy: 0.6750 - val_loss: 1.0926\nEpoch 42/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7412 - loss: 0.6789 - val_accuracy: 0.6600 - val_loss: 1.0471\nEpoch 43/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7480 - loss: 0.6838 - val_accuracy: 0.6625 - val_loss: 1.0937\nEpoch 44/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7857 - loss: 0.5996 - val_accuracy: 0.6900 - val_loss: 1.1700\nEpoch 45/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7656 - loss: 0.6365 - val_accuracy: 0.7000 - val_loss: 1.0892\nEpoch 46/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7474 - loss: 0.6620 - val_accuracy: 0.7000 - val_loss: 1.0318\nEpoch 47/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7624 - loss: 0.6182 - val_accuracy: 0.6725 - val_loss: 1.2495\nEpoch 48/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7454 - loss: 0.6708 - val_accuracy: 0.6800 - val_loss: 1.1337\nEpoch 49/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7372 - loss: 0.6488 - val_accuracy: 0.5575 - val_loss: 1.9642\nEpoch 50/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7391 - loss: 0.6739 - val_accuracy: 0.5900 - val_loss: 2.3794\nEpoch 51/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7442 - loss: 0.6601 - val_accuracy: 0.6150 - val_loss: 1.3697\nEpoch 52/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7670 - loss: 0.6541 - val_accuracy: 0.7125 - val_loss: 1.1096\nEpoch 53/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7452 - loss: 0.6268 - val_accuracy: 0.7100 - val_loss: 0.9500\nEpoch 54/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7726 - loss: 0.5665 - val_accuracy: 0.6550 - val_loss: 1.5944\nEpoch 55/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7598 - loss: 0.5904 - val_accuracy: 0.5825 - val_loss: 1.9850\nEpoch 56/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7640 - loss: 0.6061 - val_accuracy: 0.6400 - val_loss: 1.6555\nEpoch 57/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7943 - loss: 0.5309 - val_accuracy: 0.7375 - val_loss: 0.9127\nEpoch 58/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7539 - loss: 0.6038 - val_accuracy: 0.6700 - val_loss: 1.1107\nEpoch 59/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7885 - loss: 0.5421 - val_accuracy: 0.6925 - val_loss: 1.0500\nEpoch 60/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7755 - loss: 0.5710 - val_accuracy: 0.6900 - val_loss: 1.1379\nEpoch 61/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7971 - loss: 0.5106 - val_accuracy: 0.7000 - val_loss: 1.1764\nEpoch 62/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8122 - loss: 0.5512 - val_accuracy: 0.7225 - val_loss: 1.0953\nEpoch 63/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7937 - loss: 0.5239 - val_accuracy: 0.6350 - val_loss: 1.3472\nEpoch 64/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8054 - loss: 0.5023 - val_accuracy: 0.7100 - val_loss: 1.1248\nEpoch 65/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8038 - loss: 0.5194 - val_accuracy: 0.7075 - val_loss: 1.0929\nEpoch 66/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7851 - loss: 0.5752 - val_accuracy: 0.6350 - val_loss: 1.4715\nEpoch 67/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7940 - loss: 0.5099 - val_accuracy: 0.6875 - val_loss: 1.0919\nEpoch 68/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7998 - loss: 0.5278 - val_accuracy: 0.6675 - val_loss: 1.4880\nEpoch 69/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7728 - loss: 0.5951 - val_accuracy: 0.6425 - val_loss: 1.5617\nEpoch 70/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8206 - loss: 0.4881 - val_accuracy: 0.6550 - val_loss: 1.2103\nEpoch 71/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8071 - loss: 0.5067 - val_accuracy: 0.6625 - val_loss: 1.3262\nEpoch 72/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7720 - loss: 0.5703 - val_accuracy: 0.6975 - val_loss: 1.2503\nEpoch 73/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7702 - loss: 0.5865 - val_accuracy: 0.6750 - val_loss: 1.4592\nEpoch 74/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8201 - loss: 0.4751 - val_accuracy: 0.6775 - val_loss: 1.1835\nEpoch 75/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8109 - loss: 0.4801 - val_accuracy: 0.6450 - val_loss: 1.2699\nEpoch 76/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8048 - loss: 0.4987 - val_accuracy: 0.7250 - val_loss: 1.0820\nEpoch 77/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8356 - loss: 0.4726 - val_accuracy: 0.6975 - val_loss: 1.2807\nEpoch 78/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8301 - loss: 0.4561 - val_accuracy: 0.6175 - val_loss: 1.8591\nEpoch 79/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8055 - loss: 0.4764 - val_accuracy: 0.7350 - val_loss: 1.2004\nEpoch 80/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8176 - loss: 0.4901 - val_accuracy: 0.7225 - val_loss: 1.1754\nEpoch 81/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8265 - loss: 0.4760 - val_accuracy: 0.7375 - val_loss: 1.0192\nEpoch 82/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8348 - loss: 0.4253 - val_accuracy: 0.7000 - val_loss: 1.3053\nEpoch 83/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8200 - loss: 0.4704 - val_accuracy: 0.6925 - val_loss: 1.5963\nEpoch 84/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8071 - loss: 0.4793 - val_accuracy: 0.7150 - val_loss: 1.1445\nEpoch 85/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8379 - loss: 0.4257 - val_accuracy: 0.6700 - val_loss: 1.7408\nEpoch 86/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8391 - loss: 0.4575 - val_accuracy: 0.6900 - val_loss: 1.1324\nEpoch 87/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8261 - loss: 0.4655 - val_accuracy: 0.7175 - val_loss: 1.1352\nEpoch 88/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8269 - loss: 0.4312 - val_accuracy: 0.6950 - val_loss: 1.3383\nEpoch 89/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8358 - loss: 0.4312 - val_accuracy: 0.6925 - val_loss: 1.2329\nEpoch 90/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8440 - loss: 0.4271 - val_accuracy: 0.7025 - val_loss: 1.1826\nEpoch 91/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8516 - loss: 0.4152 - val_accuracy: 0.7425 - val_loss: 1.2905\nEpoch 92/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8296 - loss: 0.4279 - val_accuracy: 0.7150 - val_loss: 1.2434\nEpoch 93/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8481 - loss: 0.4087 - val_accuracy: 0.6900 - val_loss: 1.6439\nEpoch 94/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8477 - loss: 0.4429 - val_accuracy: 0.7275 - val_loss: 1.1229\nEpoch 95/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8461 - loss: 0.3978 - val_accuracy: 0.6825 - val_loss: 1.4683\nEpoch 96/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8495 - loss: 0.4171 - val_accuracy: 0.6725 - val_loss: 1.8053\nEpoch 97/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8306 - loss: 0.4476 - val_accuracy: 0.6350 - val_loss: 1.8293\nEpoch 98/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8439 - loss: 0.4375 - val_accuracy: 0.6900 - val_loss: 1.1968\nEpoch 99/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8320 - loss: 0.3986 - val_accuracy: 0.7175 - val_loss: 1.1503\nEpoch 100/100\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8603 - loss: 0.3939 - val_accuracy: 0.6950 - val_loss: 1.4295\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}